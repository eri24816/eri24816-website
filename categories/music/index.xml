<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Music on eri24816's website</title><link>https://eri24816.tw/categories/music/</link><description>Recent content in Music on eri24816's website</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 24 Aug 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://eri24816.tw/categories/music/index.xml" rel="self" type="application/rss+xml"/><item><title>Controllable music generator</title><link>https://eri24816.tw/post/controllable-music-generator/</link><pubDate>Sun, 24 Aug 2025 00:00:00 +0000</pubDate><guid>https://eri24816.tw/post/controllable-music-generator/</guid><description>&lt;p>&lt;img src="https://i.imgur.com/6oABwUs.jpeg" alt="">&lt;/p>
&lt;p>This is my first attempt to build a user interface for my music generation model (after 3 years of training music generation models and interacting with them through cli).&lt;/p>
&lt;p>The underlying model is a transformer trained to generate symbolic music auto-regressively, with a dataset consisting piano performances of pop music. Four bar-level features: chord, velocity, note density, and polyphony, can be controlled by user.&lt;/p></description></item></channel></rss>