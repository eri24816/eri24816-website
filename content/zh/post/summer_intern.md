---
title: "心得－中研院 summer intern"
date: 2022-09-06T19:25:22+08:00
draft: false
categories: "self"
image: "https://i.imgur.com/V3iXDYN.jpg"
summary: "我聽著音樂寫code，期許要讓我做的AI也做出這麼”像音樂”的音樂，同時利用我自身聽音樂的感知做為設計模型的靈感。"
---

> 2022/7/1 開始在中研院楊奕軒老師的實驗室實習的心得

很感謝老師還有學長姐花時間帶我，讓我能在前輩已走過的經驗下，在自己喜歡的領域盡情探索而不會踩太多坑。我很開心我有學到很多東西，例如把原本沒聽過的diffusion model學到可以拿來把玩、學會如何distributed training。

我不喜歡聽課，像學校期望學生做的那樣。對我來說，學東西最好的方式就是混進比我厲害的一群人之中，想辦法跟他們做一樣的事。實驗室是一個有源源不絕的新知的地方，有什麼新東西就會被貼上來討論，或是會看到有人開始著手研究。大家研究了厲害的東西，然後發paper。如果我也學著做到如此，對我的生涯是大有幫助的，且我能得到成就感。雖然不是完全確定我以後要當researcher，但如果是的話，這個實習經驗是我在成為researcher的路上重要的起步。

我之前一直在抱怨(無理取鬧)為什麼志同道合的朋友那麼難找。我喜歡ML和音樂，就算是在資工系上真的喜歡這兩者的人也很少，畢竟資訊的子領域太多了。而實習期間，我則能如願遇到領域內的佼佼者、有研究熱忱的人。這裡讓我找回離開科學班後想念的那種純粹的學術氛圍，充滿可以拿音樂、ML、”昨天train的怎麼樣”來當日常話題的人們，我覺得很舒適。

我的研究題目是用diffusion model生成鋼琴流行音樂。研究動機是我想做出好聽的音樂，但我自己沒能力，所以叫AI來做。而且如果AI能在給定的範圍內無限的sample音樂出來，就不會有聽膩的問題了。

Diffusion model算是新東西，而且我在初期實驗得到不錯的結果(發現diffusion model有能力生成好聽的鋼琴音樂)，所以我覺得這個研究蠻有發展性的。接下來還有很多測試要做，看可以往哪些應用發展。

寫code很累，因為data representation是自己設計的，我從6月中花一個月寫data pipeline，從下載、分析、過濾、轉midi、轉json、轉tensor到再轉回來。然後找一份看起來最好用的diffusion model code下來，針對生成鋼琴音樂的功能到處改，還要處理tensorboard輸出等等。

儘管如此，對音樂的興趣始終讓我不對研究感到厭煩。我聽著音樂寫code，期許要讓我做的AI也做出這麼”像音樂”的音樂，同時利用我自身聽音樂的感知做為設計模型的靈感，例如要讓模型顯性的感知到和聲，就要讓同一時間的每個音一起輸入模型；人對”和弦不同”感受的差異大於”同和弦但不同組成音”，所以也許在spectrogram上算loss比較合理。在AI能生成出稍微好聽的兩小節音樂片段時，我挑了一個片段把它拉進去DAW裡面，以其為基礎加油添醋、套各種樂器，改編成完整的音樂(如果沒有這個生成的片段，以我的功力是很難編出完整曲子的)。這個過程讓我意識到僅僅最初步的生成模型，就有提供編曲者強大靈感的能力，並期待我能進一步做出更強的應用。

由生成出來的 midi 改編的音樂:

{{<audio src="/audio/AI2_e3.mp3" caption="" >}}

![Image](https://i.imgur.com/BNhpcCO.jpg#center)


