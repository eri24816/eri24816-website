<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Highlights on eri24816's website</title><link>https://eri24816.tw/tags/highlights/</link><description>Recent content in Highlights on eri24816's website</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 24 Aug 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://eri24816.tw/tags/highlights/index.xml" rel="self" type="application/rss+xml"/><item><title>Controllable music generator</title><link>https://eri24816.tw/post/music/controllable-music-generator/</link><pubDate>Sun, 24 Aug 2025 00:00:00 +0000</pubDate><guid>https://eri24816.tw/post/music/controllable-music-generator/</guid><description>&lt;p>&lt;img src="https://i.imgur.com/6oABwUs.jpeg" alt="">&lt;/p>
&lt;p>After 3 years of training music generation models and interacting with them through CLI, this is my first attempt to build a user interface for them. Playing with it feels really great, it feels like the model is actually usable.&lt;/p>
&lt;p>There are four controllable features: chord, velocity, note density, and polyphony, where chord can be set in a per-beat granularity, and other features can be set per bar.&lt;/p>
&lt;p>The underlying model is a transformer trained to generate symbolic music auto-regressively, with a dataset consisting of piano performances of pop music.&lt;/p></description></item></channel></rss>